OPENAI_API_KEY = ""
#EMBEDDING_MODEL can be openai or vertexai or by default all-MiniLM-L6-v2
EMBEDDING_MODEL = "openai"
MY_EMBEDDING_MODEL = "bge-m3"
MY_EMBEDDING_MODEL_DIMONTION = 1024
MY_EMBEDDING_APIKEY = "sk-IY8Th3tgbOzSzl9p2cEb3f8d7aF543AfB2772d963d4a5131"
MY_EMBEDDING_URL = "https://apis.bioinforcode.com/v1"

RAGAS_EMBEDDING_MODEL = "openai"
IS_EMBEDDING = "true"
KNN_MIN_SCORE = "0.94"
# Enable Gemini (default is False) | Can be False or True
GEMINI_ENABLED = False
# Enable Google Cloud logs (default is False) | Can be False or True
GCP_LOG_METRICS_ENABLED = False
NUMBER_OF_CHUNKS_TO_COMBINE = 6
UPDATE_GRAPH_CHUNKS_PROCESSED = 20
NEO4J_URI = ""
NEO4J_USERNAME = ""
NEO4J_PASSWORD = ""
NEO4J_DATABASE = ""
AWS_ACCESS_KEY_ID =  ""
AWS_SECRET_ACCESS_KEY = ""
LANGCHAIN_API_KEY = ""
LANGCHAIN_PROJECT = ""
LANGCHAIN_TRACING_V2 = ""
LANGCHAIN_ENDPOINT = ""
GCS_FILE_CACHE = "" #save the file into GCS or local, SHould be True or False
NEO4J_USER_AGENT=""
ENABLE_USER_AGENT = ""
LLM_MODEL_CONFIG_model_version=""
ENTITY_EMBEDDING="True" # True or False
DUPLICATE_SCORE_VALUE = 0.97
DUPLICATE_TEXT_DISTANCE =3
DEFAULT_DIFFBOT_CHAT_MODEL="groq_deepseek"  #whichever model specified here , need to add config for that model in below format)
#examples

# Format: model_name,api_key
LLM_MODEL_CONFIG_openai_o1_mini="o1-mini,sk-IY8Th3tgbOzSzl9p2cEb3f8d7aF543AfB2772d963d4a5131"
LLM_MODEL_CONFIG_openai_gpt_4o_mini="gpt-4o-mini,sk-IY8Th3tgbOzSzl9p2cEb3f8d7aF543AfB2772d963d4a5131"
LLM_MODEL_CONFIG_openai_gpt_4o="gpt-4o-2024-08-06,sk-IY8Th3tgbOzSzl9p2cEb3f8d7aF543AfB2772d963d4a5131"
LLM_MODEL_CONFIG_gemini_1.5_pro="gemini-1.5-pro,sk-IY8Th3tgbOzSzl9p2cEb3f8d7aF543AfB2772d963d4a5131"
LLM_MODEL_CONFIG_gemini_2.0_flash="gemini-2.0-flash-exp,sk-IY8Th3tgbOzSzl9p2cEb3f8d7aF543AfB2772d963d4a5131"
LLM_MODEL_CONFIG_anthropic_claude_3_5_sonnet="claude-3.5-sonnet,sk-IY8Th3tgbOzSzl9p2cEb3f8d7aF543AfB2772d963d4a5131"
LLM_MODEL_CONFIG_groq_deepseek="deepseek-chat,sk-IY8Th3tgbOzSzl9p2cEb3f8d7aF543AfB2772d963d4a5131"

